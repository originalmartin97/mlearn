{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "\n",
    "- Logistic regression is an algorithm for **classification**.\n",
    "\n",
    "- Logistic regression builds a **linear model** that separates the two classes by a hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/linear_classifier.jpg\" width=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let' discuss first the **univariate** case, with a **binary target** variable and **no bias** term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/logreg_1d.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Programming Exam Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>study_time</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Beckham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica Scott</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scunner Campbell</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plain Jane</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Archie Gillis</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  study_time  result\n",
       "0     David Beckham         0.0       0\n",
       "1     Jessica Scott         7.0       1\n",
       "2      Jack Johnson         3.5       0\n",
       "3  Scunner Campbell         6.0       0\n",
       "4       Plain Jane          3.0       1\n",
       "5     Archie Gillis        15.0       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [\n",
    "    {'name': 'David Beckham',    'study_time': 0,   'result': 0},\n",
    "    {'name': 'Jessica Scott',    'study_time': 7,   'result': 1},\n",
    "    {'name': 'Jack Johnson',     'study_time': 3.5, 'result': 0},\n",
    "    {'name': 'Scunner Campbell', 'study_time': 6,   'result': 0},\n",
    "    {'name': 'Plain Jane ',      'study_time': 3,   'result': 1},\n",
    "    {'name': 'Archie Gillis',    'study_time': 15,  'result': 1},\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above toy data set contains 2 attributes of 6 students:\n",
    "- Hours spent on preparing for the exam.\n",
    "- Did the student pass the exam? (0=no, 1=yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Train a univariate logistic regression model that estimates the `result` column from the `study_time` column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input & target.\n",
    "x = df['study_time'].values # input\n",
    "y = df['result'].values     # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid function.\n",
    "import numpy as np\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(y, yhat):\n",
    "    return (-y * np.log(yhat) - (1 - y) * np.log(1 - yhat)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce(w)=4.158883  ce'(w)=-7.750000  w=0\n",
      "ce(w)=3.776799  ce'(w)=-0.787094  w=0.09358490566037736\n",
      "ce(w)=3.771515  ce'(w)=-0.031070  w=0.10666796800443652\n",
      "ce(w)=3.771506  ce'(w)=-0.000056  w=0.1072285464056069\n",
      "ce(w)=3.771506  ce'(w)=-0.000000  w=0.10722956451957244\n",
      "ce(w)=3.771506  ce'(w)=-0.000000  w=0.10722956452292766\n",
      "ce(w)=3.771506  ce'(w)=0.000000  w=0.1072295645229277\n",
      "ce(w)=3.771506  ce'(w)=0.000000  w=0.10722956452292769\n",
      "ce(w)=3.771506  ce'(w)=0.000000  w=0.10722956452292769\n",
      "ce(w)=3.771506  ce'(w)=0.000000  w=0.10722956452292769\n"
     ]
    }
   ],
   "source": [
    "w = 0 # initial model parameter\n",
    "\n",
    "for k in range(10):\n",
    "    yhat = sigmoid(x * w)\n",
    "    ce = (-y * np.log(yhat) - (1 - y) * np.log(1 - yhat)).sum()\n",
    "    ce_i = (yhat - y) @ x\n",
    "    ce_ii = (yhat * (1 - yhat)) @ x**2\n",
    "    print(f\"ce(w)={ce:.6f}  ce'(w)={ce_i:.6f}  w={w}\")\n",
    "    w = w - ce_i / ce_ii # Newton-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'P(pass the exam)')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the probability of passing the exam (according to the model)\n",
    "# as a function of the study hours!\n",
    "import matplotlib.pyplot as plt\n",
    "x2 = np.arange(-48, 48, 0.1) # study time\n",
    "yhat2 = sigmoid(x2 * w)    # predicted probability of passing the exam\n",
    "plt.plot(x2, yhat2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('study hours')\n",
    "plt.ylabel('P(pass the exam)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Wisconsin Breast Cancer Problem\n",
    "\n",
    "<img src=\"../_img/wisconsin_illustration.jpg\" width=\"200\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wisconsin Breast Cancer data set contains the attributes of 699 suspicious lesions in tissue microscopy images. The raw data is contained in [wisconsin_data.txt](../_data/wisconsin_data.txt), the description can be read in [wisconsin_names.txt](../_data/wisconsin_names.txt). The task is to estimate if the lesion is malicious (4) or benign (2), based on the image attributes of the lesion. Therefore the task is a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Train a univariate logistic regression model for each input feature separately, and measure the *average* cross-entropy of each model! Use the full data set both for training and evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names.\n",
    "names = [\n",
    "    'Sample_code_number',\n",
    "    'Clump_Thickness',\n",
    "    'Uniformity_of_Cell_Size',\n",
    "    'Uniformity_of_Cell_Shape',\n",
    "    'Marginal_Adhesion',\n",
    "    'Single_Epithelial_Cell_Size',\n",
    "    'Bare_Nuclei',\n",
    "    'Bland_Chromatin',\n",
    "    'Normal_Nucleoli',\n",
    "    'Mitoses',\n",
    "    'Class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to DataFrame.\n",
    "df = pd.read_csv('../_data/wisconsin_data.txt', sep=',', names=names, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Sample_code_number           699 non-null    int64  \n",
      " 1   Clump_Thickness              699 non-null    int64  \n",
      " 2   Uniformity_of_Cell_Size      699 non-null    int64  \n",
      " 3   Uniformity_of_Cell_Shape     699 non-null    int64  \n",
      " 4   Marginal_Adhesion            699 non-null    int64  \n",
      " 5   Single_Epithelial_Cell_Size  699 non-null    int64  \n",
      " 6   Bare_Nuclei                  683 non-null    float64\n",
      " 7   Bland_Chromatin              699 non-null    int64  \n",
      " 8   Normal_Nucleoli              699 non-null    int64  \n",
      " 9   Mitoses                      699 non-null    int64  \n",
      " 10  Class                        699 non-null    int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 60.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sample_code_number</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>617095.729819</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>870688.5</td>\n",
       "      <td>1171710.0</td>\n",
       "      <td>1238298.0</td>\n",
       "      <td>13454352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <td>699.0</td>\n",
       "      <td>4.417740e+00</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.134478e+00</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.207439e+00</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.806867e+00</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.216023e+00</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <td>683.0</td>\n",
       "      <td>3.544656e+00</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <td>699.0</td>\n",
       "      <td>3.437768e+00</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.866953e+00</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitoses</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1.589413e+00</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>699.0</td>\n",
       "      <td>2.689557e+00</td>\n",
       "      <td>0.951273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count          mean            std      min  \\\n",
       "Sample_code_number           699.0  1.071704e+06  617095.729819  61634.0   \n",
       "Clump_Thickness              699.0  4.417740e+00       2.815741      1.0   \n",
       "Uniformity_of_Cell_Size      699.0  3.134478e+00       3.051459      1.0   \n",
       "Uniformity_of_Cell_Shape     699.0  3.207439e+00       2.971913      1.0   \n",
       "Marginal_Adhesion            699.0  2.806867e+00       2.855379      1.0   \n",
       "Single_Epithelial_Cell_Size  699.0  3.216023e+00       2.214300      1.0   \n",
       "Bare_Nuclei                  683.0  3.544656e+00       3.643857      1.0   \n",
       "Bland_Chromatin              699.0  3.437768e+00       2.438364      1.0   \n",
       "Normal_Nucleoli              699.0  2.866953e+00       3.053634      1.0   \n",
       "Mitoses                      699.0  1.589413e+00       1.715078      1.0   \n",
       "Class                        699.0  2.689557e+00       0.951273      2.0   \n",
       "\n",
       "                                  25%        50%        75%         max  \n",
       "Sample_code_number           870688.5  1171710.0  1238298.0  13454352.0  \n",
       "Clump_Thickness                   2.0        4.0        6.0        10.0  \n",
       "Uniformity_of_Cell_Size           1.0        1.0        5.0        10.0  \n",
       "Uniformity_of_Cell_Shape          1.0        1.0        5.0        10.0  \n",
       "Marginal_Adhesion                 1.0        1.0        4.0        10.0  \n",
       "Single_Epithelial_Cell_Size       2.0        2.0        4.0        10.0  \n",
       "Bare_Nuclei                       1.0        1.0        6.0        10.0  \n",
       "Bland_Chromatin                   2.0        3.0        5.0        10.0  \n",
       "Normal_Nucleoli                   1.0        1.0        4.0        10.0  \n",
       "Mitoses                           1.0        1.0        1.0        10.0  \n",
       "Class                             2.0        2.0        4.0         4.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle null values.\n",
    "se = df['Bare_Nuclei']\n",
    "se.fillna(se.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_cross_entropy(y, yhat):\n",
    "    return (-y * np.log(yhat) - (1 - y) * np.log(1 - yhat)).mean()\n",
    "\n",
    "def train_logreg(x, y):\n",
    "    w = 0 # initial model parameter\n",
    "    for k in range(10):\n",
    "        yhat = sigmoid(x * w)\n",
    "        ce_i = (yhat - y) @ x\n",
    "        ce_ii = (yhat * (1 - yhat)) @ x**2\n",
    "        w = w - ce_i / ce_ii # Newton-step\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                0.6877388587845084 0.03995610011874475\n",
      "Uniformity_of_Cell_Size        0.6383720214989874 0.16899601558126182\n",
      "Uniformity_of_Cell_Shape       0.6451413035345479 0.15502997222673773\n",
      "Marginal_Adhesion              0.6590996892553264 0.14093730167294283\n",
      "Single_Epithelial_Cell_Size    0.6868149890759724 0.0582681374215134\n",
      "Bare_Nuclei                    0.6329906292130498 0.15362976756622004\n",
      "Bland_Chromatin                0.6797548410004657 0.07917958833296734\n",
      "Normal_Nucleoli                0.6512356138866332 0.15213614235880277\n",
      "Mitoses                        0.6895896950808426 0.07347703509166521\n"
     ]
    }
   ],
   "source": [
    "y = df['Class'].values // 2 - 1 # target vector\n",
    "for name in names[1:-1]:\n",
    "    x = df[name].values    # input vector\n",
    "    w = train_logreg(x, y) # train model\n",
    "    yhat = sigmoid(x * w)  # make prediction\n",
    "    ace = avg_cross_entropy(y, yhat)\n",
    "    print(f'{name:30} {ace} {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Repeat the previous experiment using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clump_Thickness                0.6877388587845084 0.03995610035279255\n",
      "Uniformity_of_Cell_Size        0.6383720214989874 0.16899601549534596\n",
      "Uniformity_of_Cell_Shape       0.6451413035345482 0.1550299722202851\n",
      "Marginal_Adhesion              0.6590996892553296 0.1409373491601551\n",
      "Single_Epithelial_Cell_Size    0.6868149890759724 0.05826813846763737\n",
      "Bare_Nuclei                    0.6329906292130497 0.15362976541621529\n",
      "Bland_Chromatin                0.6797548410004665 0.0791796082061368\n",
      "Normal_Nucleoli                0.6512356138866334 0.15213614230482528\n",
      "Mitoses                        0.6895896950808427 0.07347705088647388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss # (log_loss = avg_cross_entropy)\n",
    "\n",
    "cl = LogisticRegression(fit_intercept=False, C=np.inf)\n",
    "\n",
    "y = df['Class'].values // 2 - 1      # target vector\n",
    "for name in names[1:-1]:\n",
    "    X = df[[name]].values            # input matrix\n",
    "    cl.fit(X, y)                     # train model\n",
    "    yhat = cl.predict_proba(X)[:, 1] # make prediction\n",
    "    ace = log_loss(y, yhat)\n",
    "    print(f'{name:30} {ace} {cl.coef_[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=inf, fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=inf, fit_intercept=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=inf, fit_intercept=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the Bare_Nuclei => Class model\n",
    "X = df[['Bare_Nuclei']].values\n",
    "cl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8229258683826854"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the probability of maliciousness if Bare_Nuclei=10?\n",
    "cl.predict_proba([[10]])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Logistic Regression\n",
    "\n",
    "The previous approach can be generalized to allows multiple input features.\n",
    "\n",
    "- model's prediction: $\\hat{y} = \\sigma(Xw)$<br>\n",
    "- objective function: $CE(w) = -\\log(\\hat{y})^Ty - \\log(1 - \\hat{y})^T(1 - y)$<br>\n",
    "- gradient vector: $\\frac{d}{dw} CE(w) = X^T(\\hat{y} - y)$<br>\n",
    "- Hessian matrix: $\\left(\\frac{d}{dw}\\right)^2 CE(w) = X^T \\mathrm{diag}\\left(\\hat{y}(1 - \\hat{y})\\right) X$\n",
    "- Newton-step: $w_{\\mathrm{new}} = w - \\left[\\left(\\frac{d}{dw}\\right)^2 CE(w)\\right]^{-1} \\left[\\frac{d}{dw} CE(w)\\right]$\n",
    "\n",
    "Similarly to linear regression, the bias term can be handled by introducing a constant 1 feature.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: Train a multivariate logistic regression model and measure its *average* cross-entropy! Use the full data set both for training and evaluation! Implement the training algorithm without using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Repeat the previous experiment using scikit-learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**: Train the model on a randomly selected 70% of the data and evaluate it on the remaining 30%!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 499 is out of bounds for axis 0 with size 210",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m yhat \u001b[38;5;241m=\u001b[39m cl\u001b[38;5;241m.\u001b[39mpredict_proba(X[test_set])[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# measure average cross entropy on test set\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m log_loss(y[test_set], \u001b[43myhat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 499 is out of bounds for axis 0 with size 210"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "X = df[names[1:-1]].values       # input matrix\n",
    "y = df['Class'].values // 2 -1   # target vector\n",
    "\n",
    "# train-test split\n",
    "train_set, test_set = train_test_split(np.arange(len(y)), train_size=0.7, random_state=42)\n",
    "\n",
    "# train model on the training set\n",
    "cl = LogisticRegression(fit_intercept=False, C=np.inf, max_iter=10, solver='newton-cholesky')\n",
    "cl.fit(X[train_set], y[train_set])\n",
    "\n",
    "# make prediction on the whole data set\n",
    "yhat = cl.predict_proba(X[test_set])[:, 1]\n",
    "\n",
    "# measure average cross entropy on test set\n",
    "log_loss(y[test_set], yhat[test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# measure average cross-entropy on training set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m log_loss[y[train_set], \u001b[43myhat\u001b[49m[train_set]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yhat' is not defined"
     ]
    }
   ],
   "source": [
    "# measure average cross-entropy on training set\n",
    "log_loss[y[train_set], yhat[train_set]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# classification accuracy on test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ((\u001b[43myhat\u001b[49m[test_set] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m==\u001b[39m y[test_set])\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yhat' is not defined"
     ]
    }
   ],
   "source": [
    "# classification accuracy on test set\n",
    "((yhat[test_set] > 0.5) == y[test_set]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2    0.655222\n",
       "4    0.344778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of labels in the data set\n",
    "df.groupby('Class').size() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 2\u001b[0m accuracy_score(y[test_set], \u001b[43myhat\u001b[49m[test_set])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yhat' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y[test_set], yhat[test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K$-Fold Cross-Validation\n",
    "- Idea: Randomly split the data to $K$ roughly equal partitions and run $K$ experiments!\n",
    "- In the $i$-th experiment, partition $i$ is used as the test set and all other partitions as the training set.\n",
    "- In the end, the scores obtained from the $K$ experiments are averaged.\n",
    "- $K$-fold cross-validation is slower but more reliable than the simple train-test split.\n",
    "- In the *stratified* variant of the method, the same distribution of labels is enforced in every partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_img/cross_val.jpg\" width=\"350\" align=\"left\" style=\"opacity: 0.8\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**: Replace the train-test split to 10-fold cross valiadtion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_set, test_set \u001b[38;5;129;01min\u001b[39;00m cross_validation\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mcl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     yhat \u001b[38;5;241m=\u001b[39m cl\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     10\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(accuracy_score(y[test_set], yhat[test_set]))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cl = LogisticRegression(fit_intercept=False, C=np.inf, max_iter=10, solver='newton-cholesky')\n",
    "cross_validation = KFold(10, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "for train_set, test_set in cross_validation.split(X):\n",
    "    cl.fit(X[train_set], y[train_set])\n",
    "    yhat = cl.predict(X)\n",
    "    scores.append(accuracy_score(y[test_set], yhat[test_set]))\n",
    "    \n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
